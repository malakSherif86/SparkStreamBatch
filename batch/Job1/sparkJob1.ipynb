{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30394efd-3b3f-4548-9f63-a0e305488fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row, SQLContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .appName(\"sparkJob1\")\\\n",
    "    .config(\"spark.eventLog.logBlockUpdates.enabled\", True)\\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff6634e0-9550-4013-b6bc-e0842ef47839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking directory: /lastDEMO/spark_project/sales_transactions2/date(2024-07-06)\n",
      "/lastDEMO/spark_project/sales_transactions2/date(2024-07-06)/sales_transactions_SS_raw_*_17.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to get the last hour's date and hour\n",
    "def get_last_hour():\n",
    "    now = datetime.now() \n",
    "    last_hour = now \n",
    "    return last_hour.strftime(\"%Y-%m-%d\"), last_hour.strftime(\"%H\")\n",
    "\n",
    "# Get the date and hour for the last hour\n",
    "target_date, target_hour = get_last_hour() \n",
    "\n",
    "# Base directory where your data is stored\n",
    "base_dir = \"/lastDEMO/spark_project/sales_transactions2\"\n",
    "dynamic_dir = f\"date({target_date})\"\n",
    "\n",
    "# Full path to the directory\n",
    "directory_path = os.path.join(base_dir, dynamic_dir)\n",
    "\n",
    "# Print the directory path for debugging\n",
    "print(f\"Checking directory: {directory_path}\")\n",
    "directory_path1 = os.path.join(directory_path,f\"sales_transactions_SS_raw_*_{target_hour}.csv\" )\n",
    "print(directory_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "473e4375-d7e4-4735-b326-ff8fa91e1378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "#the right this is to but the varible insteed of the file path\n",
    "data = spark.read.csv(directory_path1, header=True)\n",
    "\n",
    "# Counting the number of rows\n",
    "count = data.count()\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ae88514-da21-4332-9a95-b9baed83051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|          Column|NullCount|\n",
      "+----------------+---------+\n",
      "|transaction_date|        0|\n",
      "|  transaction_id|        0|\n",
      "|     customer_id|        0|\n",
      "|  customer_fname|        0|\n",
      "|  cusomter_lname|        0|\n",
      "|  cusomter_email|        0|\n",
      "|  sales_agent_id|      500|\n",
      "|       branch_id|      500|\n",
      "|      product_id|        0|\n",
      "|    product_name|        0|\n",
      "|product_category|        0|\n",
      "|         offer_1|     1347|\n",
      "|         offer_2|     1356|\n",
      "|         offer_3|     1332|\n",
      "|         offer_4|     1355|\n",
      "|         offer_5|     1374|\n",
      "|           units|        0|\n",
      "|      unit_price|        0|\n",
      "|       is_online|        0|\n",
      "|  payment_method|        0|\n",
      "|shipping_address|     1000|\n",
      "+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "# Calculate the null counts for each column\n",
    "null_counts = data.select([spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in data.columns])\n",
    "\n",
    "# Convert the null counts to a list of tuples\n",
    "null_counts_list = [(c, null_counts.collect()[0][c]) for c in data.columns]\n",
    "\n",
    "# Create a new DataFrame for null counts\n",
    "null_counts_df = spark.createDataFrame(null_counts_list, [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts in tabular form\n",
    "null_counts_df.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6a48e3c-856d-4a4e-8af5-7b78ae0966c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic fill values: {'sales_agent_id': 0, 'branch_id': 0, 'shipping_address': 'not available'}\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+---------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+\n",
      "|transaction_date|  transaction_id|customer_id|customer_fname|cusomter_lname|      cusomter_email|sales_agent_id|branch_id|product_id|   product_name|product_category|offer_1|offer_2|offer_3|offer_4|offer_5|units|unit_price|is_online|payment_method|shipping_address|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+---------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+\n",
      "|       2023-5-20|trx-152546429674|      85469|     Alexander|         Brown|alexander.brown@g...|             1|        2|        22|   Coffee Maker|      Appliances|   null|   null|   null|   null|   null|   10|     79.99|       no|          Cash|   not available|\n",
      "|      2022-10-25|trx-291375327542|      85512|       William|         Brown|william.brown@gma...|             3|        1|        24|        Blender|      Appliances|   null|   null|   null|   True|   null|    5|     49.99|       no|          Cash|   not available|\n",
      "|        2022-2-5|trx-312507679871|      85484|          John|      Williams|john.williams@gma...|            10|        3|         4|     Headphones|     Electronics|   null|   null|   null|   null|   null|    1|     99.99|       no|   Credit Card|   not available|\n",
      "|      2023-10-20|trx-193384855491|      85528|     Alexander|        Miller|alexander.miller@...|             7|        2|        25|Washing Machine|      Appliances|   null|   null|   null|   null|   null|    8|    499.99|       no|          Cash|   not available|\n",
      "|      2022-11-17|trx-831626097654|      85500|          John|         Brown|john.brown@hotmai...|             5|        1|        14|         Camera|     Electronics|   null|   null|   True|   null|   null|   10|    399.99|       no|          Cash|   not available|\n",
      "|       2022-9-27|trx-158496122054|      85545|        Sophia|        Wilson|sophia.wilson@hot...|             4|        5|        14|         Camera|     Electronics|   null|   null|   null|   null|   True|    6|    399.99|       no|   Credit Card|   not available|\n",
      "|       2022-4-21|trx-722817999024|      85561|     Alexander|         Moore|alexander.moore@y...|             4|        1|        30|Electric Kettle|      Appliances|   null|   null|   null|   True|   null|    6|     24.99|       no|   Credit Card|   not available|\n",
      "|       2023-4-28|trx-813287633702|      85520|     Alexander|        Wilson|alexander.wilson@...|             1|        1|        26| Vacuum Cleaner|      Appliances|   null|   null|   null|   null|   null|    4|    199.99|       no|          Cash|   not available|\n",
      "|        2023-3-8|trx-219568257432|      85488|       Michael|        Miller|michael.miller@ya...|             6|        2|        18|          Boots|        Footwear|   null|   null|   null|   null|   null|   10|    149.99|       no|   Credit Card|   not available|\n",
      "|       2023-6-17|trx-352160720823|      85466|       Michael|         Brown|michael.brown@yah...|             5|        2|        16|          Skirt|        Clothing|   null|   null|   null|   null|   null|    8|     39.99|       no|          Cash|   not available|\n",
      "|       2022-8-28|trx-895389231641|      85559|          John|        Taylor|john.taylor@yahoo...|             6|        5|        14|         Camera|     Electronics|   null|   null|   null|   null|   null|    6|    399.99|       no|          Cash|   not available|\n",
      "|      2023-11-19|trx-820309386661|      85527|     Alexander|         Davis|alexander.davis@y...|             7|        2|        22|   Coffee Maker|      Appliances|   null|   null|   null|   null|   null|    6|     79.99|       no|   Credit Card|   not available|\n",
      "|       2022-3-22|trx-974983174642|      85502|       Michael|         Brown|michael.brown@hot...|             4|        5|         5|        T-Shirt|        Clothing|   True|   null|   null|   null|   null|   10|     19.99|       no|          Cash|   not available|\n",
      "|       2022-9-27|trx-119174604031|      85508|         James|         Smith|james.smith@yahoo...|             1|        3|         9|          Boots|        Footwear|   null|   null|   null|   null|   null|    1|    129.99|       no|   Credit Card|   not available|\n",
      "|        2022-4-3|trx-474525094645|      85549|          Emma|       Johnson|emma.johnson@hotm...|             2|        3|         2|     Smartphone|     Electronics|   null|   null|   null|   null|   null|    9|    699.99|       no|   Credit Card|   not available|\n",
      "|      2022-12-14|trx-355633008132|      85483|          John|       Johnson|john.johnson@yaho...|             9|        5|        27|           Iron|      Appliances|   null|   True|   null|   null|   null|    9|     29.99|       no|   Credit Card|   not available|\n",
      "|       2023-4-14|trx-490311940006|      85496|         James|         Davis|james.davis@yahoo...|             8|        2|        19|        Sandals|        Footwear|   null|   True|   null|   null|   null|    2|     29.99|       no|   Credit Card|   not available|\n",
      "|       2023-1-19|trx-132205124356|      85507|           Ava|        Miller|ava.miller@outloo...|             2|        2|        28|     Hair Dryer|      Appliances|   null|   null|   null|   null|   null|    3|     19.99|       no|          Cash|   not available|\n",
      "|      2023-10-14|trx-276319959382|      85543|        Olivia|         Brown|olivia.brown@outl...|            10|        5|        24|        Blender|      Appliances|   null|   null|   null|   null|   null|   10|     49.99|       no|          Cash|   not available|\n",
      "|       2022-3-24|trx-024853282614|      85518|        Sophia|         Brown|sophia.brown@gmai...|             1|        4|         3|         Tablet|     Electronics|   null|   null|   True|   null|   null|    1|    299.99|       no|          Cash|   not available|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+---------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns to fill with their default values\n",
    "fill_values = {\n",
    "    \"sales_agent_id\": 0,\n",
    "    \"branch_id\": 0,\n",
    "    \"shipping_address\": \"not available\",\n",
    "    \"source\": \"not found\",\n",
    "    \"logs\": \"not found\"\n",
    "}\n",
    "\n",
    "# Get the current columns in the DataFrame\n",
    "current_columns = data.columns\n",
    "\n",
    "# Filter the fill_values dictionary to include only the columns that are present in the DataFrame\n",
    "dynamic_fill_values = {col: fill_values[col] for col in fill_values if col in current_columns}\n",
    "\n",
    "# Print the dynamic fill values dictionary for debugging\n",
    "print(f\"Dynamic fill values: {dynamic_fill_values}\")\n",
    "\n",
    "# Apply the fill operation with the dynamically constructed dictionary\n",
    "data = data.na.fill(dynamic_fill_values)\n",
    "\n",
    "# Show the first few rows to verify the changes (optional)\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf69dbe4-4481-4164-8e45-79f01e3921ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of duplicate rows: None\n"
     ]
    }
   ],
   "source": [
    "#check for duplictes\n",
    "\n",
    "duplicates = data.groupBy(data.columns).count().filter(col(\"count\") > 1)\n",
    "\n",
    "# Sum the counts of duplicate rows and subtract the number of unique duplicate groups\n",
    "total_duplicate_count = duplicates.select(spark_sum(col(\"count\") - 1).alias(\"total_duplicates\")).collect()[0][\"total_duplicates\"]\n",
    "\n",
    "print(f\"Total number of duplicate rows: {total_duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b06469a0-2034-41bd-a16b-f164082f8438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplictes\n",
    "data = data.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6acb9f1d-949d-47aa-bfec-9c2d757e7091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+\n",
      "|transaction_date|  transaction_id|customer_id|customer_fname|cusomter_lname|      cusomter_email|sales_agent_id|branch_id|product_id|product_name|product_category|offer_1|offer_2|offer_3|offer_4|offer_5|units|unit_price|is_online|payment_method|shipping_address|discounts|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+\n",
      "|        2022-9-7|trx-672299323430|      85536|          John|         Brown|john.brown@hotmai...|             1|        3|        20|       Heels|        Footwear|   null|   null|   null|   null|   null|    3|     59.99|       no|          Cash|   not available|      0.0|\n",
      "|       2022-6-15|trx-817564853293|      85483|          John|       Johnson|john.johnson@yaho...|             3|        3|        17|      Blouse|        Clothing|   null|   null|   null|   null|   True|    8|     29.99|       no|   Credit Card|   not available|     0.25|\n",
      "|       2023-3-25|trx-641718779539|      85532|       Michael|         Brown|michael.brown@yah...|             5|        5|        11|          TV|     Electronics|   null|   null|   null|   null|   null|    6|    899.99|       no|          Cash|   not available|      0.0|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#callculate discount \n",
    "from pyspark.sql.functions import when, col\n",
    "data = data.withColumn(\n",
    "    \"discounts\",\n",
    "    when(col(\"offer_1\") == True, 0.05)\n",
    "    .when(col(\"offer_2\") == True, 0.10)\n",
    "    .when(col(\"offer_3\") == True, 0.15)\n",
    "    .when(col(\"offer_4\") == True, 0.20)\n",
    "    .when(col(\"offer_5\") == True, 0.25)\n",
    "    .otherwise(0.0)\n",
    ")\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4ebeece-c49c-4a17-99da-1ba4b176e421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+---------+---------+\n",
      "|transaction_date|  transaction_id|customer_id|customer_fname|cusomter_lname|      cusomter_email|sales_agent_id|branch_id|product_id|product_name|product_category|offer_1|offer_2|offer_3|offer_4|offer_5|units|unit_price|is_online|payment_method|shipping_address|     logs|   source|discounts|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+---------+---------+\n",
      "|       2022-3-21|trx-240718692783|      85519|           Mia|         Moore|mia.moore@outlook...|             9|        5|        22|Coffee Maker|      Appliances|   null|   True|   null|   null|   null|    5|     79.99|       no|   Credit Card|   not available|not found|not found|      0.1|\n",
      "|       2023-11-8|trx-252492897739|      85487|          John|        Miller|john.miller@hotma...|            10|        1|        21|   Microwave|      Appliances|   null|   null|   null|   null|   null|    7|    129.99|       no|          Cash|   not available|not found|not found|      0.0|\n",
      "|       2023-4-16|trx-729363962425|      85494|       William|         Jones|william.jones@out...|            11|        2|         7|       Dress|        Clothing|   null|   True|   null|   null|   null|    2|     59.99|       no|          Cash|   not available|not found|not found|      0.1|\n",
      "|        2022-3-7|trx-591430414291|      85471|        Olivia|         Smith|olivia.smith@yaho...|             2|        3|         2|  Smartphone|     Electronics|   null|   null|   null|   null|   null|    1|    699.99|       no|   Credit Card|   not available|not found|not found|      0.0|\n",
      "|       2023-10-4|trx-951171719752|      85488|          Emma|       Johnson|emma.johnson@gmai...|             3|        6|        27|        Iron|      Appliances|   null|   null|   True|   null|   null|    2|     29.99|       no|   Credit Card|   not available|not found|not found|     0.15|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0349526a-a1fa-475a-b485-6f09dc1d6298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+---------+--------------+--------------------+---------+-----+\n",
      "|transaction_date|  transaction_id|customer_id|customer_fname|cusomter_lname|      cusomter_email|sales_agent_id|branch_id|product_id|     product_name|product_category|units|unit_price|is_online|payment_method|    shipping_address|discounts|offer|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+---------+--------------+--------------------+---------+-----+\n",
      "|        2022-9-7|trx-672299323430|      85536|          John|         Brown|john.brown@hotmai...|             1|        3|        20|            Heels|        Footwear|    3|     59.99|       no|          Cash|       not available|      0.0| null|\n",
      "|       2022-6-15|trx-817564853293|      85483|          John|       Johnson|john.johnson@yaho...|             3|        3|        17|           Blouse|        Clothing|    8|     29.99|       no|   Credit Card|       not available|     0.25|    5|\n",
      "|       2023-3-25|trx-641718779539|      85532|       Michael|         Brown|michael.brown@yah...|             5|        5|        11|               TV|     Electronics|    6|    899.99|       no|          Cash|       not available|      0.0| null|\n",
      "|       2023-3-18|trx-488140115830|      85472|           Ava|         Smith|ava.smith@outlook...|             2|        3|        25|  Washing Machine|      Appliances|    4|    499.99|       no|          Cash|       not available|      0.2|    4|\n",
      "|       2022-8-18|trx-732483728822|      85543|        Olivia|         Brown|olivia.brown@outl...|             0|        0|         1|           Laptop|     Electronics|   10|    999.99|      yes|   Credit Card|3483 Canyon Creek...|      0.2|    4|\n",
      "|       2023-2-17|trx-073978015822|      85464|          Emma|      Williams|emma.williams@out...|             0|        0|        18|            Boots|        Footwear|    4|    149.99|      yes|        Stripe|9008 Grayson Grov...|      0.0| null|\n",
      "|       2023-1-12|trx-852858823303|      85532|       Michael|         Brown|michael.brown@yah...|             1|        5|        26|   Vacuum Cleaner|      Appliances|    6|    199.99|       no|   Credit Card|       not available|     0.05|    1|\n",
      "|       2022-8-15|trx-633681330064|      85507|           Ava|        Miller|ava.miller@outloo...|             5|        2|        29|Hair Straightener|      Appliances|    3|     39.99|       no|   Credit Card|       not available|      0.2|    4|\n",
      "|        2023-5-8|trx-408942530842|      85491|     Alexander|        Wilson|alexander.wilson@...|            10|        2|         6|            Jeans|        Clothing|    4|     49.99|       no|          Cash|       not available|      0.0| null|\n",
      "|       2023-1-14|trx-061411588899|      85486|         James|       Johnson|james.johnson@yah...|             0|        0|         9|            Boots|        Footwear|    7|    129.99|      yes|        PayPal|8028 North 56th L...|      0.0| null|\n",
      "|       2022-6-25|trx-848112316525|      85504|          John|       Johnson|john.johnson@hotm...|             0|        0|         7|            Dress|        Clothing|    9|     59.99|      yes|   Credit Card|1815 Grove Hill L...|      0.0| null|\n",
      "|        2022-1-1|trx-961186738199|      85540|       William|        Wilson|william.wilson@gm...|             0|        0|         9|            Boots|        Footwear|    8|    129.99|      yes|        PayPal|45 Parsons Avenue...|     0.25|    5|\n",
      "|      2023-10-10|trx-742866826677|      85552|        Olivia|         Davis|olivia.davis@outl...|             0|        0|        19|          Sandals|        Footwear|    8|     29.99|      yes|   Credit Card|7725 Ney Avenue/O...|     0.25|    5|\n",
      "|       2023-4-14|trx-615744130593|      85484|          John|      Williams|john.williams@gma...|             8|        1|        15|           Hoodie|        Clothing|    5|     29.99|       no|   Credit Card|       not available|     0.25|    5|\n",
      "|       2023-3-25|trx-528657438563|      85546|     Alexander|       Johnson|alexander.johnson...|             5|        4|        19|          Sandals|        Footwear|    3|     29.99|       no|   Credit Card|       not available|     0.25|    5|\n",
      "|       2023-9-24|trx-011554971106|      85558|           Ava|      Williams|ava.williams@yaho...|             1|        4|        14|           Camera|     Electronics|    5|    399.99|       no|   Credit Card|       not available|     0.15|    3|\n",
      "|      2022-12-17|trx-936284967406|      85524|          John|         Jones|john.jones@yahoo....|             3|        2|        30|  Electric Kettle|      Appliances|    9|     24.99|       no|          Cash|       not available|      0.0| null|\n",
      "|       2022-3-22|trx-752540628294|      85552|        Olivia|         Davis|olivia.davis@outl...|             2|        3|        19|          Sandals|        Footwear|   10|     29.99|       no|          Cash|       not available|      0.2|    4|\n",
      "|       2022-2-23|trx-616906345392|      85546|     Alexander|       Johnson|alexander.johnson...|             1|        4|         2|       Smartphone|     Electronics|    6|    699.99|       no|          Cash|       not available|      0.0| null|\n",
      "|        2022-7-1|trx-804384518230|      85546|     Alexander|       Johnson|alexander.johnson...|             6|        4|        24|          Blender|      Appliances|    9|     49.99|       no|          Cash|       not available|     0.05|    1|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+---------+--------------+--------------------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce, col, lit, when\n",
    "\n",
    "columns = ['offer_1', 'offer_2', 'offer_3', 'offer_4','offer_5']\n",
    "\n",
    "\n",
    "\n",
    "# Create the 'offer' column based on the condition\n",
    "df = data.withColumn('offer',\n",
    "                   when(col('offer_1') == 'True', 1)\n",
    "                   .when(col('offer_2') == 'True', 2)\n",
    "                   .when(col('offer_3') == 'True', 3)\n",
    "                   .when(col('offer_4') == 'True', 4)\n",
    "                   .when(col('offer_5') == 'True', 5)\n",
    "                   .otherwise(None))\n",
    "\n",
    "# Drop the original offer columns if needed\n",
    "data = df.drop(*columns)\n",
    "\n",
    "# Show the result\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84628594-eab1-44e1-9be8-640f7b964a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "deb1a20a-c1c6-40f1-9e22-d879d7fbdf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+---------+--------------+--------------------+---------+-----+-----------------+---------+-----------+\n",
      "|transaction_date|  transaction_id|customer_id|customer_fname|cusomter_lname|      cusomter_email|sales_agent_id|branch_id|product_id|     product_name|product_category|units|unit_price|is_online|payment_method|    shipping_address|discounts|offer|             city|    state|postal_code|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+---------+--------------+--------------------+---------+-----+-----------------+---------+-----------+\n",
      "|        2022-9-7|trx-672299323430|      85536|          John|         Brown|john.brown@hotmai...|             1|        3|        20|            Heels|        Footwear|    3|     59.99|       no|          Cash|       not available|      0.0| null|        not found|not found|  not found|\n",
      "|       2022-6-15|trx-817564853293|      85483|          John|       Johnson|john.johnson@yaho...|             3|        3|        17|           Blouse|        Clothing|    8|     29.99|       no|   Credit Card|       not available|     0.25|    5|        not found|not found|  not found|\n",
      "|       2023-3-25|trx-641718779539|      85532|       Michael|         Brown|michael.brown@yah...|             5|        5|        11|               TV|     Electronics|    6|    899.99|       no|          Cash|       not available|      0.0| null|        not found|not found|  not found|\n",
      "|       2023-3-18|trx-488140115830|      85472|           Ava|         Smith|ava.smith@outlook...|             2|        3|        25|  Washing Machine|      Appliances|    4|    499.99|       no|          Cash|       not available|      0.2|    4|        not found|not found|  not found|\n",
      "|       2022-8-18|trx-732483728822|      85543|        Olivia|         Brown|olivia.brown@outl...|             0|        0|         1|           Laptop|     Electronics|   10|    999.99|      yes|   Credit Card|3483 Canyon Creek...|      0.2|    4|         San Jose|       CA|      95132|\n",
      "|       2023-2-17|trx-073978015822|      85464|          Emma|      Williams|emma.williams@out...|             0|        0|        18|            Boots|        Footwear|    4|    149.99|      yes|        Stripe|9008 Grayson Grov...|      0.0| null|       Montgomery|       AL|      36117|\n",
      "|       2023-1-12|trx-852858823303|      85532|       Michael|         Brown|michael.brown@yah...|             1|        5|        26|   Vacuum Cleaner|      Appliances|    6|    199.99|       no|   Credit Card|       not available|     0.05|    1|        not found|not found|  not found|\n",
      "|       2022-8-15|trx-633681330064|      85507|           Ava|        Miller|ava.miller@outloo...|             5|        2|        29|Hair Straightener|      Appliances|    3|     39.99|       no|   Credit Card|       not available|      0.2|    4|        not found|not found|  not found|\n",
      "|        2023-5-8|trx-408942530842|      85491|     Alexander|        Wilson|alexander.wilson@...|            10|        2|         6|            Jeans|        Clothing|    4|     49.99|       no|          Cash|       not available|      0.0| null|        not found|not found|  not found|\n",
      "|       2023-1-14|trx-061411588899|      85486|         James|       Johnson|james.johnson@yah...|             0|        0|         9|            Boots|        Footwear|    7|    129.99|      yes|        PayPal|8028 North 56th L...|      0.0| null|         Glendale|       AZ|      85302|\n",
      "|       2022-6-25|trx-848112316525|      85504|          John|       Johnson|john.johnson@hotm...|             0|        0|         7|            Dress|        Clothing|    9|     59.99|      yes|   Credit Card|1815 Grove Hill L...|      0.0| null|       Montgomery|       AL|      36106|\n",
      "|        2022-1-1|trx-961186738199|      85540|       William|        Wilson|william.wilson@gm...|             0|        0|         9|            Boots|        Footwear|    8|    129.99|      yes|        PayPal|45 Parsons Avenue...|     0.25|    5|Saint Albans City|       VT|      05478|\n",
      "|      2023-10-10|trx-742866826677|      85552|        Olivia|         Davis|olivia.davis@outl...|             0|        0|        19|          Sandals|        Footwear|    8|     29.99|      yes|   Credit Card|7725 Ney Avenue/O...|     0.25|    5|          Oakland|       CA|      94605|\n",
      "|       2023-4-14|trx-615744130593|      85484|          John|      Williams|john.williams@gma...|             8|        1|        15|           Hoodie|        Clothing|    5|     29.99|       no|   Credit Card|       not available|     0.25|    5|        not found|not found|  not found|\n",
      "|       2023-3-25|trx-528657438563|      85546|     Alexander|       Johnson|alexander.johnson...|             5|        4|        19|          Sandals|        Footwear|    3|     29.99|       no|   Credit Card|       not available|     0.25|    5|        not found|not found|  not found|\n",
      "|       2023-9-24|trx-011554971106|      85558|           Ava|      Williams|ava.williams@yaho...|             1|        4|        14|           Camera|     Electronics|    5|    399.99|       no|   Credit Card|       not available|     0.15|    3|        not found|not found|  not found|\n",
      "|      2022-12-17|trx-936284967406|      85524|          John|         Jones|john.jones@yahoo....|             3|        2|        30|  Electric Kettle|      Appliances|    9|     24.99|       no|          Cash|       not available|      0.0| null|        not found|not found|  not found|\n",
      "|       2022-3-22|trx-752540628294|      85552|        Olivia|         Davis|olivia.davis@outl...|             2|        3|        19|          Sandals|        Footwear|   10|     29.99|       no|          Cash|       not available|      0.2|    4|        not found|not found|  not found|\n",
      "|       2022-2-23|trx-616906345392|      85546|     Alexander|       Johnson|alexander.johnson...|             1|        4|         2|       Smartphone|     Electronics|    6|    699.99|       no|          Cash|       not available|      0.0| null|        not found|not found|  not found|\n",
      "|        2022-7-1|trx-804384518230|      85546|     Alexander|       Johnson|alexander.johnson...|             6|        4|        24|          Blender|      Appliances|    9|     49.99|       no|          Cash|       not available|     0.05|    1|        not found|not found|  not found|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+---------+--------------+--------------------+---------+-----+-----------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col, when\n",
    "\n",
    "# Split the shipping_address into components\n",
    "df = data.withColumn('address_split', split(df['shipping_address'], '/'))\n",
    "\n",
    "# Create new columns for city, state, and postal_code based on the condition\n",
    "df = df.withColumn(\n",
    "    'city',\n",
    "    when(col('is_online') == 'yes', col('address_split').getItem(1))\n",
    "    .otherwise(\"not found\")\n",
    ").withColumn(\n",
    "    'state',\n",
    "    when(col('is_online') == 'yes', col('address_split').getItem(2))\n",
    "    .otherwise(\"not found\")\n",
    ").withColumn(\n",
    "    'postal_code',\n",
    "    when(col('is_online') == 'yes', col('address_split').getItem(3))\n",
    "    .otherwise(\"not found\")\n",
    ")\n",
    "\n",
    "# Drop the temporary address_split column if not needed\n",
    "data= df.drop('address_split')\n",
    "\n",
    "# Show the result\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01f82cee-bd3e-4f07-9e57-32896b5cf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add total paid \n",
    "data = data.withColumn(\n",
    "    \"total_paid\",\n",
    "    (col(\"units\") * col(\"unit_price\")) - (col(\"units\") * col(\"unit_price\") * col(\"discounts\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23478f4c-735c-4b1c-924b-cd693bda3d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(transaction_date='2022-9-7', transaction_id='trx-672299323430', customer_id='85536', customer_fname='John', cusomter_lname='Brown', cusomter_email='john.brown@hotmail.com', sales_agent_id='1', branch_id='3', product_id='20', product_name='Heels', product_category='Footwear', units='3', unit_price='59.99', is_online='no', payment_method='Cash', shipping_address='not available', discounts=0.0, offer=None, city='not found', state='not found', postal_code='not found', total_paid=179.97)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#handling email problems \n",
    "from pyspark.sql.functions import regexp_replace\n",
    "data = data.withColumn(\"cusomter_email\", regexp_replace(\"cusomter_email\", r\"\\.com.*\", \".com\"))\n",
    "display(data.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8508704d-f755-4f87-8e45-308a8e3f4d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('transaction_date', 'string'), ('transaction_id', 'string'), ('customer_id', 'string'), ('customer_fname', 'string'), ('cusomter_lname', 'string'), ('cusomter_email', 'string'), ('sales_agent_id', 'string'), ('branch_id', 'string'), ('product_id', 'string'), ('product_name', 'string'), ('product_category', 'string'), ('units', 'string'), ('unit_price', 'string'), ('is_online', 'string'), ('payment_method', 'string'), ('shipping_address', 'string'), ('discounts', 'double'), ('offer', 'int'), ('city', 'string'), ('state', 'string'), ('postal_code', 'string'), ('total_paid', 'double')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import current_date, year, month\n",
    "from pyspark.sql.functions import to_date\n",
    "print(data.dtypes)\n",
    "data = data.withColumn(\"transaction_date\", to_date(data[\"transaction_date\"], \"yyyy-M-d\"))\n",
    "# Add the current extraction date\n",
    "data = data.withColumn(\"extraction_date\", current_date())\n",
    "\n",
    "# Extract year and month from the extraction date\n",
    "data = data.withColumn(\"Extraction_Year\", year(data[\"extraction_date\"])) \\\n",
    "           .withColumn(\"Extraction_Month\", month(data[\"extraction_date\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ded4ed7d-93ce-467a-a028-3dfaf855e2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Years Count: 1\n",
      "Distinct Months Count: 1\n",
      "Row counts grouped by Year and Month:\n",
      "+----------------+-----+\n",
      "|Extraction_Month|count|\n",
      "+----------------+-----+\n",
      "|               7| 1500|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get info about the data \n",
    "distinct_years_count = data.select(\"Extraction_Year\").distinct().count()\n",
    "print(f\"Distinct Years Count: {distinct_years_count}\")\n",
    "\n",
    "# Count distinct months\n",
    "distinct_months_count = data.select(\"Extraction_Month\").distinct().count()\n",
    "print(f\"Distinct Months Count: {distinct_months_count}\")\n",
    "\n",
    "# Count rows grouped by year and month\n",
    "grouped_counts = data.groupBy( \"Extraction_Month\").count()\n",
    "\n",
    "# Show the grouped counts\n",
    "print(\"Row counts grouped by Year and Month:\")\n",
    "grouped_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8420e0d-2010-4da3-868f-69a8e1d1e5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "+--------------------+-----+\n",
      "|SPARK_PARTITION_ID()|count|\n",
      "+--------------------+-----+\n",
      "|                 148|    7|\n",
      "|                  31|    7|\n",
      "|                  85|    8|\n",
      "|                 137|    9|\n",
      "|                  65|   10|\n",
      "|                  53|    8|\n",
      "|                 133|    6|\n",
      "|                  78|    3|\n",
      "|                 108|    6|\n",
      "|                 155|    4|\n",
      "|                  34|    5|\n",
      "|                 193|    8|\n",
      "|                 101|    7|\n",
      "|                 115|    8|\n",
      "|                 126|   10|\n",
      "|                  81|   10|\n",
      "|                  28|    5|\n",
      "|                 183|    7|\n",
      "|                  76|   12|\n",
      "|                  26|    8|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "\n",
    "rdd = data.rdd\n",
    "num_partitions = rdd.getNumPartitions()\n",
    "print(num_partitions)\n",
    "data.rdd.glom().map(lambda p: len(p)).collect()\n",
    "data.rdd.glom().map(lambda p: set([i[-1] for i in p])).collect()\n",
    "data.groupBy(f.spark_partition_id()).count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01caaac9-0e02-4d65-aeeb-b59fe266c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b40d91d7-05fa-45c3-a5b3-677d2678fc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          namespace|\n",
      "+-------------------+\n",
      "|                db2|\n",
      "|            default|\n",
      "|              newdb|\n",
      "|             newdb1|\n",
      "|       sparkproject|\n",
      "|      sparkproject1|\n",
      "|      sparkproject2|\n",
      "|transactiondatabase|\n",
      "|     transactionsdb|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS TransactionDataBase \")\n",
    "databases = spark.sql(\"SHOW DATABASES\")\n",
    "databases.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f55f8fb7-93be-4158-86f4-16a33756432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Save the DataFrame as a Hive table with multi-level partitioning and bucketing\n",
    "    single_partition_df.write.format(\"orc\") \\\n",
    "        .bucketBy(8, \"product_name\") \\\n",
    "        .sortBy(\"product_name\") \\\n",
    "        .partitionBy(\"Extraction_Year\", \"Extraction_Month\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(\"TransactionsDB.Transactions_Table\")\n",
    "\n",
    "    print(\"Table created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating table: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04091f21-e483-4848-9438-dc042298a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, col, year, month, dayofmonth, quarter, date_format\n",
    "customer_dim_df = data.select(\n",
    "    \"customer_id\",\n",
    "    \"customer_fname\",\n",
    "    \"cusomter_lname\",  # Keep the typo if it exists in the data\n",
    "    \"cusomter_email\"\n",
    ").distinct()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "169d019a-0585-4e91-920e-0047ac4093dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dim_df = data.select(\n",
    "    \"product_id\",\n",
    "    \"product_name\",\n",
    "    \"product_category\"\n",
    ").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d21e9b21-5143-463a-ba36-aaa840761a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, lit\n",
    "\n",
    "# Correctly using concat with lit\n",
    "sales_data_with_location = data.select(\n",
    "    concat(col(\"city\"), lit(\"-\"), col(\"state\"), lit(\"-\"), col(\"postal_code\")).alias(\"location_id\"),\n",
    "    \"city\",\n",
    "    \"state\",\n",
    "    \"postal_code\"\n",
    ").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f783a64d-f7b6-4161-bc00-e431639ac28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth, month, year, quarter, date_format\n",
    "\n",
    "date_dim_df = data.select(\n",
    "    \"transaction_date\",\n",
    "    dayofmonth(\"transaction_date\").alias(\"day\"),\n",
    "    month(\"transaction_date\").alias(\"month\"),\n",
    "    year(\"transaction_date\").alias(\"year\"),\n",
    "    quarter(\"transaction_date\").alias(\"quarter\"),\n",
    "    date_format(\"transaction_date\", \"EEEE\").alias(\"day_name\")\n",
    ").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2db9695b-a2c4-4f25-8a20-8a50df6fac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "fact_df = data.select(\n",
    "    \"transaction_id\",\n",
    "    \"customer_id\",\n",
    "    \"sales_agent_id\",\n",
    "    \"branch_id\",\n",
    "    \"product_id\",\n",
    "    F.concat_ws(\"-\", \"city\", \"state\", \"postal_code\").alias(\"location_id\"),\n",
    "    \"transaction_date\",\n",
    "    \"offer\",\n",
    "    \"is_online\",\n",
    "    F.col(\"units\").cast(\"int\").alias(\"units\"),\n",
    "    F.col(\"unit_price\").cast(\"double\").alias(\"unit_price\"),\n",
    "    \"total_paid\",\n",
    "    \"Extraction_Year\",\n",
    "    \"Extraction_Month\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88aad7a3-f0e7-43cf-802f-3d44a59d82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+---------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+---------+------------------+---------------+----------------+\n",
      "|transaction_date|  transaction_id|customer_id|customer_fname|cusomter_lname|      cusomter_email|sales_agent_id|branch_id|product_id|   product_name|product_category|offer_1|offer_2|offer_3|offer_4|offer_5|units|unit_price|is_online|payment_method|shipping_address|discounts|     city|        total_paid|extraction_date|Extraction_Month|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+---------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+---------+------------------+---------------+----------------+\n",
      "|      2022-04-21|trx-722817999024|      85561|     Alexander|         Moore|alexander.moore@y...|             4|        1|        30|Electric Kettle|      Appliances|  false|  false|  false|   True|  false|    6|     24.99|       no|   Credit Card|   not available|      0.2|not found|           119.952|     2024-07-05|               7|\n",
      "|      2023-05-10|trx-647743402933|      85558|           Ava|      Williams|ava.williams@yaho...|            10|        5|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|    1|     24.99|       no|          Cash|   not available|      0.0|not found|             24.99|     2024-07-05|               7|\n",
      "|      2023-08-18|trx-841564414963|      85535|       William|        Taylor|william.taylor@ho...|             5|        3|        30|Electric Kettle|      Appliances|  false|  false|   True|  false|  false|    8|     24.99|       no|   Credit Card|   not available|     0.15|not found|           169.932|     2024-07-05|               7|\n",
      "|      2022-01-16|trx-283758758161|      85473|        Sophia|        Miller|sophia.miller@yah...|             3|        5|        30|Electric Kettle|      Appliances|  false|  false|   True|  false|  false|    6|     24.99|       no|   Credit Card|   not available|     0.15|not found|           127.449|     2024-07-05|               7|\n",
      "|      2022-08-17|trx-410328091125|      85468|       William|         Davis|william.davis@yah...|             5|        2|        30|Electric Kettle|      Appliances|   True|  false|  false|  false|  false|    8|     24.99|       no|          Cash|   not available|     0.05|not found|189.92399999999998|     2024-07-05|               7|\n",
      "|      2023-04-17|trx-683938966513|      85466|       Michael|         Brown|michael.brown@yah...|             9|        5|        30|Electric Kettle|      Appliances|  false|  false|   True|  false|  false|    9|     24.99|       no|          Cash|   not available|     0.15|not found|          191.1735|     2024-07-05|               7|\n",
      "|      2023-06-26|trx-696535134068|      85552|        Olivia|         Davis|olivia.davis@outl...|             7|        3|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|   True|    2|     24.99|       no|          Cash|   not available|     0.25|not found|            37.485|     2024-07-05|               7|\n",
      "|      2022-06-05|trx-130979929170|      85520|     Alexander|        Wilson|alexander.wilson@...|             1|        4|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|   10|     24.99|       no|   Credit Card|   not available|      0.0|not found|249.89999999999998|     2024-07-05|               7|\n",
      "|      2022-09-25|trx-540740082897|      85514|       Michael|         Brown|michael.brown@out...|             6|        1|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|    7|     24.99|       no|   Credit Card|   not available|      0.0|not found|174.92999999999998|     2024-07-05|               7|\n",
      "|      2022-11-12|trx-617576769444|      85507|           Ava|        Miller|ava.miller@outloo...|             5|        4|        30|Electric Kettle|      Appliances|  false|   True|  false|  false|  false|    7|     24.99|       no|          Cash|   not available|      0.1|not found|157.43699999999998|     2024-07-05|               7|\n",
      "|      2023-07-22|trx-630649759709|      85469|     Alexander|         Brown|alexander.brown@g...|             1|        1|        30|Electric Kettle|      Appliances|  false|  false|   True|  false|  false|    5|     24.99|       no|   Credit Card|   not available|     0.15|not found|          106.2075|     2024-07-05|               7|\n",
      "|      2022-03-13|trx-282242636607|      85533|           Ava|        Taylor|ava.taylor@yahoo.com|            10|        4|        30|Electric Kettle|      Appliances|   True|  false|  false|  false|  false|    6|     24.99|       no|          Cash|   not available|     0.05|not found|142.44299999999998|     2024-07-05|               7|\n",
      "|      2022-07-24|trx-432534329316|      85538|         James|         Smith|james.smith@yahoo...|             4|        5|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|    9|     24.99|       no|   Credit Card|   not available|      0.0|not found|            224.91|     2024-07-05|               7|\n",
      "|      2022-12-17|trx-936284967406|      85524|          John|         Jones|john.jones@yahoo.com|             3|        2|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|    9|     24.99|       no|          Cash|   not available|      0.0|not found|            224.91|     2024-07-05|               7|\n",
      "|      2023-01-14|trx-698565261187|      85495|        Olivia|         Moore|olivia.moore@yaho...|             9|        4|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|    4|     24.99|       no|          Cash|   not available|      0.0|not found|             99.96|     2024-07-05|               7|\n",
      "|      2022-07-14|trx-941504169670|      85523|           Mia|        Wilson|mia.wilson@gmail.com|            10|        3|        30|Electric Kettle|      Appliances|   True|  false|  false|  false|  false|    2|     24.99|       no|          Cash|   not available|     0.05|not found|47.480999999999995|     2024-07-05|               7|\n",
      "|      2022-09-18|trx-428704698763|      85511|           Ava|         Moore| ava.moore@gmail.com|             3|        4|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|    5|     24.99|       no|          Cash|   not available|      0.0|not found|124.94999999999999|     2024-07-05|               7|\n",
      "|      2023-05-19|trx-985339341968|      85533|           Ava|        Taylor|ava.taylor@yahoo.com|             5|        2|        30|Electric Kettle|      Appliances|  false|  false|  false|   True|  false|    9|     24.99|       no|   Credit Card|   not available|      0.2|not found|           179.928|     2024-07-05|               7|\n",
      "|      2022-09-15|trx-029065219829|      85526|       Michael|        Miller|michael.miller@ou...|             8|        4|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|    7|     24.99|       no|          Cash|   not available|      0.0|not found|174.92999999999998|     2024-07-05|               7|\n",
      "|      2022-09-27|trx-825118580916|      85517|        Olivia|         Jones|olivia.jones@hotm...|             4|        4|        30|Electric Kettle|      Appliances|  false|  false|  false|  false|  false|    6|     24.99|       no|   Credit Card|   not available|      0.0|not found|            149.94|     2024-07-05|               7|\n",
      "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+---------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+----------------+---------+---------+------------------+---------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.orc(\"/user/hive/warehouse/transactionsdb.db/transactions_table/*\")\n",
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dbc53b5-7874-4807-9d4f-7e7143da54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If renaming the table is an option, use underscore instead of hyphen\n",
    "customer_dim_df.write.format(\"orc\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"TransactionsDB.Customer1_Dim\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9952c2e-adc1-486d-a77f-6418d1a4dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dim_df.write.format(\"orc\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"TransactionsDB.Product1_Dim\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c005456e-3674-43be-bffd-54e0fc32c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_with_location.write.format(\"orc\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"TransactionsDB.Location1_Dim\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dccfa8d0-210d-4c17-8fe5-574b0902e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dim_df.write.format(\"orc\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"TransactionsDB.Date1_Dim\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0383e9d4-125f-43cf-82af-357b44ea8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df.write.format(\"orc\") \\\n",
    "    .partitionBy(\"Extraction_Year\", \"Extraction_Month\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"TransactionsDB.Transaction_FactTable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e59bb603-3b71-4f44-acc1-673896084cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|      transaction_id|   string|   null|\n",
      "|         customer_id|   string|   null|\n",
      "|      sales_agent_id|   string|   null|\n",
      "|           branch_id|   string|   null|\n",
      "|          product_id|   string|   null|\n",
      "|         location_id|   string|   null|\n",
      "|    transaction_date|     date|   null|\n",
      "|               offer|      int|   null|\n",
      "|           is_online|   string|   null|\n",
      "|               units|      int|   null|\n",
      "|          unit_price|   double|   null|\n",
      "|          total_paid|   double|   null|\n",
      "|     Extraction_Year|      int|   null|\n",
      "|    Extraction_Month|      int|   null|\n",
      "|# Partition Infor...|         |       |\n",
      "|          # col_name|data_type|comment|\n",
      "|     Extraction_Year|      int|   null|\n",
      "|    Extraction_Month|      int|   null|\n",
      "|                    |         |       |\n",
      "|# Detailed Table ...|         |       |\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_description = spark.sql(f\"DESCRIBE FORMATTED TransactionsDB.Transaction_FactTable\")\n",
    "table_description.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b3d29b0-d673-40f2-8160-26e855be5c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-------+\n",
      "|        col_name|data_type|comment|\n",
      "+----------------+---------+-------+\n",
      "|transaction_date|     date|   null|\n",
      "|             day|      int|   null|\n",
      "|           month|      int|   null|\n",
      "|            year|      int|   null|\n",
      "|         quarter|      int|   null|\n",
      "|        day_name|   string|   null|\n",
      "+----------------+---------+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_description = spark.sql(f\"DESCRIBE FORMATTED TransactionsDB.Date1_Dim\")\n",
    "table_description.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8fcf3558-0972-4f5b-8caa-29dcdab5c43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|location_id|   string|   null|\n",
      "|       city|   string|   null|\n",
      "|      state|   string|   null|\n",
      "|postal_code|   string|   null|\n",
      "+-----------+---------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_description = spark.sql(f\"DESCRIBE FORMATTED TransactionsDB.Location1_Dim\")\n",
    "table_description.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1db33ffd-9b11-4f94-a966-3d041f2a397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|      transaction_id|   string|   null|\n",
      "|         customer_id|   string|   null|\n",
      "|      sales_agent_id|   string|   null|\n",
      "|           branch_id|   string|   null|\n",
      "|          product_id|   string|   null|\n",
      "|         location_id|   string|   null|\n",
      "|    transaction_date|     date|   null|\n",
      "|               offer|      int|   null|\n",
      "|           is_online|   string|   null|\n",
      "|               units|      int|   null|\n",
      "|          unit_price|   double|   null|\n",
      "|          total_paid|   double|   null|\n",
      "|     Extraction_Year|      int|   null|\n",
      "|    Extraction_Month|      int|   null|\n",
      "|# Partition Infor...|         |       |\n",
      "|          # col_name|data_type|comment|\n",
      "|     Extraction_Year|      int|   null|\n",
      "|    Extraction_Month|      int|   null|\n",
      "|                    |         |       |\n",
      "|# Detailed Table ...|         |       |\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_description = spark.sql(f\"DESCRIBE FORMATTED TransactionsDB.Transaction_FactTable\")\n",
    "table_description.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19bf14e2-83c9-4bef-b4e7-e8e2266af85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-------+\n",
      "|        col_name|data_type|comment|\n",
      "+----------------+---------+-------+\n",
      "|      product_id|   string|   null|\n",
      "|    product_name|   string|   null|\n",
      "|product_category|   string|   null|\n",
      "+----------------+---------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_description = spark.sql(f\"DESCRIBE FORMATTED TransactionsDB.Product1_Dim\")\n",
    "table_description.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a79fa9d-347e-4a61-9973-cd80537604e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|         customer_id|              string|   null|\n",
      "|      customer_fname|              string|   null|\n",
      "|      cusomter_lname|              string|   null|\n",
      "|      cusomter_email|              string|   null|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|            Database|      transactionsdb|       |\n",
      "|               Table|       customer1_dim|       |\n",
      "|               Owner|           itversity|       |\n",
      "|        Created Time|Sat Jul 06 08:12:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.1.2|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|                 orc|       |\n",
      "|          Statistics|          5275 bytes|       |\n",
      "|            Location|hdfs://localhost:...|       |\n",
      "|       Serde Library|org.apache.hadoop...|       |\n",
      "|         InputFormat|org.apache.hadoop...|       |\n",
      "|        OutputFormat|org.apache.hadoop...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_description = spark.sql(f\"DESCRIBE FORMATTED TransactionsDB.Customer1_Dim\")\n",
    "table_description.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "259ab4eb-0611-4c5a-b48e-de3deb8f7db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+\n",
      "|     product_name|total_sold_units|\n",
      "+-----------------+----------------+\n",
      "|            Boots|          204041|\n",
      "|          Sandals|          203997|\n",
      "|           Laptop|          103629|\n",
      "|       Smartphone|          103275|\n",
      "|Hair Straightener|          103257|\n",
      "|            Skirt|          103004|\n",
      "|          Toaster|          102779|\n",
      "|        Microwave|          102702|\n",
      "|          T-Shirt|          102469|\n",
      "|            Dress|          102253|\n",
      "+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#total sold unites by product\n",
    "most_selling_products_df = spark.sql(\"\"\"\n",
    "SELECT p.product_name, SUM(f.units) AS total_sold_units\n",
    "FROM TransactionsDB.Transaction_FactTable f\n",
    "JOIN TransactionsDB.Product1_Dim p ON f.product_id = p.product_id\n",
    "GROUP BY p.product_name\n",
    "ORDER BY total_sold_units DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "most_selling_products_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42d1d376-1a0d-4143-8ea6-09aa9f019b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>offer</th><th>total_redeemed</th></tr>\n",
       "<tr><td>offer_2</td><td>55696</td></tr>\n",
       "<tr><td>offer_1</td><td>55665</td></tr>\n",
       "<tr><td>offer_3</td><td>55563</td></tr>\n",
       "<tr><td>offer_5</td><td>55542</td></tr>\n",
       "<tr><td>offer_4</td><td>55534</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+--------------+\n",
       "|  offer|total_redeemed|\n",
       "+-------+--------------+\n",
       "|offer_2|         55696|\n",
       "|offer_1|         55665|\n",
       "|offer_3|         55563|\n",
       "|offer_5|         55542|\n",
       "|offer_4|         55534|\n",
       "+-------+--------------+"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many time did the cutomer use the offer , kol offer zahr kam mara \n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE offer\n",
    "            WHEN 1 THEN 'offer_1'\n",
    "            WHEN 2 THEN 'offer_2'\n",
    "            WHEN 3 THEN 'offer_3'\n",
    "            WHEN 4 THEN 'offer_4'\n",
    "            WHEN 5 THEN 'offer_5'\n",
    "        END AS offer,\n",
    "        COUNT(*) AS total_redeemed\n",
    "    FROM TransactionsDB.Transaction_FactTable\n",
    "    where offer is not null\n",
    "    GROUP BY offer\n",
    "    ORDER BY total_redeemed DESC\n",
    "    LIMIT 5\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32d67b1c-ce4e-422f-898a-6b8de2c0030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_name</th><th>most_redeemed_offer</th><th>total_redeemed</th></tr>\n",
       "<tr><td>Hair Dryer</td><td>offer_1</td><td>1981</td></tr>\n",
       "<tr><td>Skirt</td><td>offer_3</td><td>1958</td></tr>\n",
       "<tr><td>Toaster</td><td>offer_1</td><td>1941</td></tr>\n",
       "<tr><td>T-Shirt</td><td>offer_2</td><td>1937</td></tr>\n",
       "<tr><td>Laptop</td><td>offer_5</td><td>1932</td></tr>\n",
       "<tr><td>Hair Straightener</td><td>offer_3</td><td>1931</td></tr>\n",
       "<tr><td>Washing Machine</td><td>offer_2</td><td>1929</td></tr>\n",
       "<tr><td>Smartphone</td><td>offer_3</td><td>1927</td></tr>\n",
       "<tr><td>Iron</td><td>offer_4</td><td>1924</td></tr>\n",
       "<tr><td>Camera</td><td>offer_3</td><td>1916</td></tr>\n",
       "<tr><td>Sandals</td><td>offer_4</td><td>1908</td></tr>\n",
       "<tr><td>Tablet</td><td>offer_2</td><td>1898</td></tr>\n",
       "<tr><td>Hoodie</td><td>offer_2</td><td>1896</td></tr>\n",
       "<tr><td>Headphones</td><td>offer_1</td><td>1896</td></tr>\n",
       "<tr><td>Printer</td><td>offer_3</td><td>1894</td></tr>\n",
       "<tr><td>Boots</td><td>offer_2</td><td>1893</td></tr>\n",
       "<tr><td>Sneakers</td><td>offer_3</td><td>1892</td></tr>\n",
       "<tr><td>Sandals</td><td>offer_5</td><td>1889</td></tr>\n",
       "<tr><td>Dress</td><td>offer_1</td><td>1887</td></tr>\n",
       "<tr><td>Coffee Maker</td><td>offer_1</td><td>1881</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------------+-------------------+--------------+\n",
       "|     product_name|most_redeemed_offer|total_redeemed|\n",
       "+-----------------+-------------------+--------------+\n",
       "|       Hair Dryer|            offer_1|          1981|\n",
       "|            Skirt|            offer_3|          1958|\n",
       "|          Toaster|            offer_1|          1941|\n",
       "|          T-Shirt|            offer_2|          1937|\n",
       "|           Laptop|            offer_5|          1932|\n",
       "|Hair Straightener|            offer_3|          1931|\n",
       "|  Washing Machine|            offer_2|          1929|\n",
       "|       Smartphone|            offer_3|          1927|\n",
       "|             Iron|            offer_4|          1924|\n",
       "|           Camera|            offer_3|          1916|\n",
       "|          Sandals|            offer_4|          1908|\n",
       "|           Tablet|            offer_2|          1898|\n",
       "|           Hoodie|            offer_2|          1896|\n",
       "|       Headphones|            offer_1|          1896|\n",
       "|          Printer|            offer_3|          1894|\n",
       "|            Boots|            offer_2|          1893|\n",
       "|         Sneakers|            offer_3|          1892|\n",
       "|          Sandals|            offer_5|          1889|\n",
       "|            Dress|            offer_1|          1887|\n",
       "|     Coffee Maker|            offer_1|          1881|\n",
       "+-----------------+-------------------+--------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a3la offer zahr per product, w zahr kam mara m3 l product \n",
    "spark.sql(\"\"\"\n",
    "    WITH offer_details AS (\n",
    "        SELECT product_id,offer,COUNT(*) AS total_redeemed FROM TransactionsDB.Transaction_FactTable\n",
    "        WHERE offer IS NOT NULL GROUP BY product_id, offer ),\n",
    "    ranked_offers AS (\n",
    "        SELECT  product_id,offer,total_redeemed,\n",
    "            ROW_NUMBER() OVER (PARTITION BY product_id ORDER BY total_redeemed DESC) AS rank\n",
    "        FROM offer_details)\n",
    "    SELECT  p.product_name,\n",
    "        CASE \n",
    "            WHEN ro.offer = 1 THEN 'offer_1'\n",
    "            WHEN ro.offer = 2 THEN 'offer_2'\n",
    "            WHEN ro.offer = 3 THEN 'offer_3'\n",
    "            WHEN ro.offer = 4 THEN 'offer_4'\n",
    "            WHEN ro.offer = 5 THEN 'offer_5'\n",
    "            ELSE 'other_offer'\n",
    "        END AS most_redeemed_offer,\n",
    "        ro.total_redeemed\n",
    "    FROM ranked_offers ro\n",
    "    JOIN TransactionsDB.Product1_Dim p ON ro.product_id = p.product_id\n",
    "    WHERE ro.rank = 1\n",
    "    ORDER BY ro.total_redeemed DESC\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f98df-1668-4458-b319-373182bbf90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.get(\"spark.sql.warehouse.dir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2fbd56c-036f-4518-bcec-e09a3b67f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|         city|online_sales|\n",
      "+-------------+------------+\n",
      "|        Linda|     2189.48|\n",
      "|      Fairfax|     3328.56|\n",
      "| Tyngsborough|     3717.47|\n",
      "|     Oakhurst|     3802.57|\n",
      "|Nichols Hills|     3887.52|\n",
      "|       Palmer|     4116.54|\n",
      "|  Wheat Ridge|      4287.4|\n",
      "|     Redlands|     4485.43|\n",
      "| West Windsor|     4533.49|\n",
      "|  North Adams|     4580.31|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lowest_online_sales_cities_df = spark.sql(\"\"\"\n",
    "SELECT l.city, round(SUM(f.total_paid),2) AS online_sales\n",
    "FROM  TransactionsDB.Transaction_FactTable f\n",
    "JOIN TransactionsDB.Location1_Dim l ON f.location_id = l.location_id\n",
    "WHERE f.is_online = 'yes'\n",
    "GROUP BY l.city\n",
    "ORDER BY online_sales ASC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "lowest_online_sales_cities_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e6adb-8ece-466a-b958-65413aca9ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
